# Copyright (c) 2024 Alibaba Inc (authors: Xiang Lyu)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
import os
import sys

# Fix DeepSpeed CUDA check issue before importing any transformers modules
os.environ['DS_BUILD_OPS'] = '0'
os.environ['DS_BUILD_FUSED_ADAM'] = '0'
os.environ['DS_BUILD_CPU_ADAM'] = '0'
os.environ['DS_BUILD_UTILS'] = '0'

# Fix MKL threading layer conflict
os.environ['MKL_THREADING_LAYER'] = 'GNU'
os.environ['MKL_SERVICE_FORCE_INTEL'] = '1'

import argparse
import logging
import json
import time

# é…ç½®æ—¥èªŒæ ¼å¼
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# é™ä½å…¶ä»–æ¨¡çµ„çš„æ—¥èªŒç´šåˆ¥
logging.getLogger('matplotlib').setLevel(logging.WARNING)
logging.getLogger('uvicorn').setLevel(logging.WARNING)
logging.getLogger('uvicorn.access').setLevel(logging.WARNING)

from fastapi import FastAPI, UploadFile, Form, File, HTTPException
from fastapi.responses import StreamingResponse, Response
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
import numpy as np
import io
import wave
ROOT_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.append('{}/../../..'.format(ROOT_DIR))
sys.path.append('{}/../../../third_party/Matcha-TTS'.format(ROOT_DIR))

# Register custom vLLM model before importing CosyVoice
try:
    from vllm import ModelRegistry
    from cosyvoice.vllm.cosyvoice2 import CosyVoice2ForCausalLM
    ModelRegistry.register_model("CosyVoice2ForCausalLM", CosyVoice2ForCausalLM)
    logging.info("Successfully registered CosyVoice2ForCausalLM with vLLM")
except ImportError:
    logging.warning("vLLM not available, skipping custom model registration")

from cosyvoice.cli.cosyvoice import CosyVoice, CosyVoice2
from cosyvoice.utils.file_utils import load_wav
from cosyvoice.utils.common import set_all_random_seed

app = FastAPI()
# set cross region allowance
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"])


def generate_data(model_output):
    for i in model_output:
        tts_audio = (i['tts_speech'].numpy() * (2 ** 15)).astype(np.int16).tobytes()
        yield tts_audio


def load_voice_config():
    """è¼‰å…¥è²éŸ³é…ç½®æª”æ¡ˆï¼Œå„ªå…ˆä½¿ç”¨ local é…ç½®"""
    local_config_path = os.path.join(ROOT_DIR, '../../../config/voices.local.json')
    example_config_path = os.path.join(ROOT_DIR, '../../../config/voices.example.json')
    
    # å„ªå…ˆè®€å– local é…ç½®
    if os.path.exists(local_config_path):
        config_path = local_config_path
        print(f"ä½¿ç”¨å€‹äººé…ç½®: {config_path}")
    else:
        config_path = example_config_path
        print(f"ä½¿ç”¨ç¯„ä¾‹é…ç½®: {config_path}")
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="è²éŸ³é…ç½®æª”æ¡ˆä¸å­˜åœ¨")
    except json.JSONDecodeError:
        raise HTTPException(status_code=500, detail="è²éŸ³é…ç½®æª”æ¡ˆæ ¼å¼éŒ¯èª¤")


def get_voice_by_id(voice_id):
    """æ ¹æ“š voice_id ç²å–è²éŸ³é…ç½®"""
    config = load_voice_config()
    for voice in config['voices']:
        if voice['id'] == voice_id:
            return voice
    raise HTTPException(status_code=404, detail=f"æ‰¾ä¸åˆ°è²éŸ³é…ç½®: {voice_id}")


def load_audio_sample(audio_file):
    """è¼‰å…¥èªéŸ³æ¨£æœ¬æª”æ¡ˆ"""
    audio_path = os.path.join(ROOT_DIR, '../../../config/audio_samples', audio_file)
    if not os.path.exists(audio_path):
        raise HTTPException(status_code=404, detail=f"èªéŸ³æ¨£æœ¬æª”æ¡ˆä¸å­˜åœ¨: {audio_file}")
    return load_wav(audio_path, 16000)


@app.get("/inference_sft")
@app.post("/inference_sft")
async def inference_sft(tts_text: str = Form(), spk_id: str = Form()):
    model_output = cosyvoice.inference_sft(tts_text, spk_id)
    return StreamingResponse(generate_data(model_output))


@app.get("/inference_zero_shot")
@app.post("/inference_zero_shot")
async def inference_zero_shot(tts_text: str = Form(), prompt_text: str = Form(), prompt_wav: UploadFile = File(), seed: int = Form(0)):
    set_all_random_seed(seed)
    print(f"ç¨®å­ç¢¼: {seed}")
    prompt_speech_16k = load_wav(prompt_wav.file, 16000)
    model_output = cosyvoice.inference_zero_shot(tts_text, prompt_text, prompt_speech_16k)
    return StreamingResponse(generate_data(model_output))


@app.get("/inference_zero_shot_wav")
@app.post("/inference_zero_shot_wav")
async def inference_zero_shot_wav(tts_text: str = Form(), prompt_text: str = Form(), prompt_wav: UploadFile = File(), seed: int = Form(0)):
    set_all_random_seed(seed)
    print(f"ç¨®å­ç¢¼: {seed}")
    prompt_speech_16k = load_wav(prompt_wav.file, 16000)
    model_output = cosyvoice.inference_zero_shot(tts_text, prompt_text, prompt_speech_16k)
    
    # å°‡æ¨¡å‹è¼¸å‡ºè½‰æ›ç‚ºWAVæ ¼å¼
    audio_data = []
    for i in model_output:
        # tts_speech çš„å½¢ç‹€æ˜¯ (1, n_samples),éœ€è¦å±•å¹³ç‚º (n_samples,)
        audio_data.append(i['tts_speech'].numpy().flatten())
    
    # åˆä½µæ‰€æœ‰éŸ³é »æ•¸æ“š
    if audio_data:
        combined_audio = np.concatenate(audio_data)
        # è½‰æ›ç‚º16ä½æ•´æ•¸æ ¼å¼
        audio_int16 = (combined_audio * (2 ** 15)).astype(np.int16)
        
        # å‰µå»ºWAVæª”æ¡ˆ
        wav_buffer = io.BytesIO()
        with wave.open(wav_buffer, 'wb') as wav_file:
            wav_file.setnchannels(1)  # å–®è²é“
            wav_file.setsampwidth(2)  # 16ä½ = 2å­—ç¯€
            wav_file.setframerate(22050)  # æ¡æ¨£ç‡ï¼Œèˆ‡load_wavçš„æ¡æ¨£ç‡ä¸€è‡´
            wav_file.writeframes(audio_int16.tobytes())
        
        wav_buffer.seek(0)
        return Response(
            content=wav_buffer.getvalue(),
            media_type="audio/wav",
            headers={"Content-Disposition": "attachment; filename=output.wav"}
        )
    else:
        return Response(content=b"", media_type="audio/wav")


@app.get("/voices")
async def get_voices():
    """ç²å–å¯ç”¨çš„è²éŸ³é…ç½®åˆ—è¡¨"""
    try:
        config = load_voice_config()
        return config
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/inference_with_voice_config")
@app.post("/inference_with_voice_config")
async def inference_with_voice_config(tts_text: str = Form(), voice_id: str = Form(), original_text: str = Form(None)):
    """ä½¿ç”¨é é…ç½®è²éŸ³é€²è¡ŒèªéŸ³åˆæˆ"""
    try:
        # è¨˜éŒ„é–‹å§‹æ™‚é–“
        start_time = time.time()
        
        # ç²å–è²éŸ³é…ç½®
        voice_config = get_voice_by_id(voice_id)
        
        # è¨˜éŒ„åŸå§‹æ–‡å­—å’Œè½‰æ›å¾Œçš„æ–‡å­—
        print("\n" + "="*60)
        if original_text and original_text != tts_text:
            print(f"ğŸ™ï¸  èªéŸ³ç”Ÿæˆè«‹æ±‚")
            print(f"åŸå§‹æ–‡å­—: {original_text}")
            print(f"å°èªæ–‡å­—: {tts_text}")
            print(f"ä½¿ç”¨è²éŸ³: {voice_config['name']} ({voice_id})")
        else:
            print(f"ğŸ™ï¸  èªéŸ³ç”Ÿæˆè«‹æ±‚")
            print(f"è¼¸å…¥æ–‡å­—: {tts_text}")
            print(f"ä½¿ç”¨è²éŸ³: {voice_config['name']} ({voice_id})")
        print("="*60)
        
        # è¨­å®šéš¨æ©Ÿç¨®å­
        seed = voice_config.get('seed', 0)
        set_all_random_seed(seed)
        
        # è¼‰å…¥èªéŸ³æ¨£æœ¬
        prompt_speech_16k = load_audio_sample(voice_config['audio_file'])
        
        # é€²è¡ŒèªéŸ³åˆæˆ
        model_output = cosyvoice.inference_zero_shot(
            tts_text, 
            voice_config['prompt_text'], 
            prompt_speech_16k
        )
        
        # å°‡æ¨¡å‹è¼¸å‡ºè½‰æ›ç‚ºWAVæ ¼å¼
        audio_data = []
        for i in model_output:
            # tts_speech çš„å½¢ç‹€æ˜¯ (1, n_samples),éœ€è¦å±•å¹³ç‚º (n_samples,)
            audio_data.append(i['tts_speech'].numpy().flatten())
        
        # åˆä½µæ‰€æœ‰éŸ³é »æ•¸æ“š
        if audio_data:
            combined_audio = np.concatenate(audio_data)
            # è½‰æ›ç‚º16ä½æ•´æ•¸æ ¼å¼
            audio_int16 = (combined_audio * (2 ** 15)).astype(np.int16)
            
            # å‰µå»ºWAVæª”æ¡ˆ
            wav_buffer = io.BytesIO()
            with wave.open(wav_buffer, 'wb') as wav_file:
                wav_file.setnchannels(1)  # å–®è²é“
                wav_file.setsampwidth(2)  # 16ä½ = 2å­—ç¯€
                wav_file.setframerate(22050)  # æ¡æ¨£ç‡
                wav_file.writeframes(audio_int16.tobytes())
            
            wav_buffer.seek(0)
            
            # è¨˜éŒ„çµæŸæ™‚é–“å’Œç¸½è€—æ™‚
            end_time = time.time()
            elapsed_time = end_time - start_time
            print(f"âœ… èªéŸ³ç”Ÿæˆå®Œæˆ,è€—æ™‚: {elapsed_time:.2f} ç§’")
            print("="*60 + "\n")
            
            return Response(
                content=wav_buffer.getvalue(),
                media_type="audio/wav",
                headers={"Content-Disposition": f"attachment; filename={voice_id}_output.wav"}
            )
        else:
            return Response(content=b"", media_type="audio/wav")
            
    except Exception as e:
        print(f"âŒ èªéŸ³åˆæˆéŒ¯èª¤: {str(e)}")
        raise HTTPException(status_code=500, detail=f"èªéŸ³åˆæˆå¤±æ•—: {str(e)}")


@app.get("/inference_cross_lingual")
@app.post("/inference_cross_lingual")
async def inference_cross_lingual(tts_text: str = Form(), prompt_wav: UploadFile = File()):
    prompt_speech_16k = load_wav(prompt_wav.file, 16000)
    model_output = cosyvoice.inference_cross_lingual(tts_text, prompt_speech_16k)
    return StreamingResponse(generate_data(model_output))


@app.get("/inference_instruct")
@app.post("/inference_instruct")
async def inference_instruct(tts_text: str = Form(), spk_id: str = Form(), instruct_text: str = Form()):
    model_output = cosyvoice.inference_instruct(tts_text, spk_id, instruct_text)
    return StreamingResponse(generate_data(model_output))


@app.get("/inference_instruct2")
@app.post("/inference_instruct2")
async def inference_instruct2(tts_text: str = Form(), instruct_text: str = Form(), prompt_wav: UploadFile = File()):
    prompt_speech_16k = load_wav(prompt_wav.file, 16000)
    model_output = cosyvoice.inference_instruct2(tts_text, instruct_text, prompt_speech_16k)
    return StreamingResponse(generate_data(model_output))


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--port',
                        type=int,
                        default=50000)
    parser.add_argument('--model_dir',
                        type=str,
                        default='iic/CosyVoice-300M',
                        help='local path or modelscope repo id')
    parser.add_argument('--load_vllm',
                        action='store_true',
                        help='enable vllm acceleration for faster inference')
    args = parser.parse_args()
    try:
        cosyvoice = CosyVoice(args.model_dir)
    except Exception:
        try:
            cosyvoice = CosyVoice2(args.model_dir, load_vllm=args.load_vllm)
        except Exception:
            raise TypeError('no valid model_type!')
    uvicorn.run(app, host="0.0.0.0", port=args.port)
